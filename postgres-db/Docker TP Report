TP Report

Adminer data
System: PostgreSQL
Server: my-db-container
Username: usr
Password: pwd
Database: db

1-1 For which reason is it better to run the container with a flag -e to give the environment variables rather than
put them directly in the Dockerfile?

Because it helps with security (sets an environment) and makes it flexible for usage (no need to rebuild).

1-2 Why do we need a volume to be attached to our postgres container?

So the data can be kept intact if the container is modified in any way, since the data is stored in the host system

1-3 Document your database container essentials: commands and Dockerfile.

Dockerfile:

FROM postgres:17.2-alpine

ENV POSTGRES_DB=db \
    POSTGRES_USER=usr \
    POSTGRES_PASSWORD=pwd

COPY 01-CreateScheme.sql /docker-entrypoint-initdb.d/
COPY 02-InsertData.sql /docker-entrypoint-initdb.d/

Build command:

docker build -t my-postgres-initdb .

Run command (with volume):

docker run -d \
  --name my-db-container \
  --network app-network \
  -v postgres-data:/var/lib/postgresql/data \
  my-postgres-initdb

1-4 Why do we need a multistage build? And explain each step of this dockerfile.

It helps keep the image a small size, separates build dependencies from runtime, helps with security and cleanliness.

It has a build and a runtime stage, which helps build the workinf directory and then runds the application.

1-5 Why do we need a reverse proxy?

As it acts as an intermediary between clients and backend servers, it helps with security, caching, load balancing and simplifies the access of clients.

1-6 Why is docker-compose so important?

Because it permits the user to define and manage multi-container applications with a single YAML file. Instead of running each container manually, you can start, stop, and configure entire environments (like backend + database + reverse proxy) with one command. It simplifies orchestration, development, and deployment.

1-7 Document docker-compose most important commands.

docker-compose up
Starts all services defined in the docker-compose.yml.

docker-compose up --build
Builds images and starts services.

docker-compose down
Stops and removes containers, networks, and volumes created by up.

docker-compose ps
Lists all running services.

docker-compose logs
Shows logs from all containers.

1-8 Document your docker-compose file.

version: '3.8'

services:
  simple-api-backend:
    build: ./backend-api
    ports:
      - "8081:8080"
    networks:
      - app-network

  reverse-proxy:
    image: httpd:2.4
    ports:
      - "8080:8080"
    volumes:
      - ./simple-http-server/config/my-proxy.conf:/usr/local/apache2/conf/extra/httpd-my-proxy.conf
    command: >
      sh -c "echo 'Include conf/extra/httpd-my-proxy.conf' >> /usr/local/apache2/conf/httpd.conf && httpd-foreground"
    depends_on:
      - simple-api-backend
    networks:
      - app-network

networks:
  app-network:

1-9 Document your publication commands and published images in dockerhub.

# Step 1: Login to DockerHub
docker login

# Step 2: Tag the local image
docker tag session1-docker-simple-api-backend:latest jochystudent/simple-api-backend:1.0

# Step 3: Push the image to DockerHub
docker push jochystudent/simple-api-backend:1.0

1-10 Why do we put our images into an online repo?

So we can:

Share them with teammates or deploy to other machines easily

Integrate them into CI/CD pipelines

Avoid rebuilding the image every time

Track versions and updates

Make the image accessible from anywhere (cloud, servers, dev machines)